{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "%matplotlib inline\n",
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from helpers import *\n",
    "from processing import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "data_path = \"data/dataset/\"\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(data_path ,sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((328135, 321), (109379, 321), (328135,), (328135,), (109379,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View shape of the dataset\n",
    "x_train.shape, x_test.shape, y_train.shape, train_ids.shape, test_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 321 features.\n",
    "- `x_train` contains the training data and it has 328 135 data entries (before cleaning).\n",
    "- `x_test` contains the test data and it has 109 379 data entires (before cleaning).\n",
    "- The `y` vector corresponds to the true values of the output (the variable we wish to predict). The output describes whether a person is diagnosed with MICHD or not. It is binary, -1 or +1, where -1 means no MICHD and +1 means MICHD. There are 328 135 data points (before cleaning).\n",
    "- `train_ids` and `test_ids` are numpy arrays. Their values correspond to the ids of the data entries of train data and test data, respectively. Therefore, the length of `train_ids` and `test_ids` correspond to the number of data entries for both train and test data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.3000000e+01 1.1000000e+01 1.1162015e+07 ...           nan\n",
      "            nan 2.0000000e+00]\n",
      " [3.3000000e+01 1.2000000e+01 1.2152015e+07 ...           nan\n",
      "            nan           nan]\n",
      " [2.0000000e+01 1.0000000e+01 1.0202015e+07 ... 1.0000000e+00\n",
      "  2.0000000e+00 2.0000000e+00]\n",
      " [4.2000000e+01 6.0000000e+00 6.1820150e+06 ... 2.0000000e+00\n",
      "  2.0000000e+00 2.0000000e+00]\n",
      " [2.4000000e+01 1.1000000e+01 1.1062015e+07 ... 9.0000000e+00\n",
      "  9.0000000e+00 2.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# View the few first and last rows of the dataset\n",
    "print(x_train[:5])  # First 5 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.9000000e+01 7.0000000e+00 1.1232015e+07 ...           nan\n",
      "            nan 2.0000000e+00]\n",
      " [5.1000000e+01 5.0000000e+00 6.0820150e+06 ...           nan\n",
      "            nan 1.0000000e+00]\n",
      " [3.9000000e+01 1.0000000e+01 1.0202015e+07 ... 2.0000000e+00\n",
      "  2.0000000e+00 2.0000000e+00]\n",
      " [3.3000000e+01 1.2000000e+01 1.2302015e+07 ...           nan\n",
      "            nan 2.0000000e+00]\n",
      " [3.2000000e+01 9.0000000e+00 9.1220150e+06 ...           nan\n",
      "            nan 2.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[-5:])  # Last 5 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Rid of Useless Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out which features are unimportant, we take a look at the column names of the dataset.\n",
    "\n",
    "After taking a closer look at the features, we decide to remove the columns as done below. They were removed for either of these reasons:\n",
    "- The columns were not relevant to the goal of our project (e.g. State, Income, etc.)\n",
    "- The columns represented questions about a specific subject that were later regrouped into a single feature (e.g. for Cholesterol, many questions were asked to the participants. One final feature summarized the findings. We only keep this final feature.)\n",
    "- The columns had too many null values, becoming irrelevant. For this, we define a threshold of 70% of null values. If a column has more than 70% of null values, we remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the new training set: (328135, 251)\n"
     ]
    }
   ],
   "source": [
    "x_train_new = x_train.copy()\n",
    "\n",
    "# We define manually all columns we want to remove\n",
    "columns_to_remove = set()\n",
    "columns_to_remove.update(range(50))         \n",
    "columns_to_remove.update(range(1, 14))      \n",
    "columns_to_remove.update(range(2, 44))      \n",
    "columns_to_remove.update(range(13, 37))     \n",
    "columns_to_remove.update(range(16, 37))     \n",
    "columns_to_remove.update(range(42, 56))     \n",
    "columns_to_remove.update(range(52, 66))     \n",
    "columns_to_remove.update([78, 79, 80])      \n",
    "columns_to_remove.update([72])             # remove height in inches to only keep height in meters\n",
    "\n",
    "columns_to_remove = sorted(columns_to_remove)\n",
    " \n",
    "x_train_new = np.delete(x_train_new, columns_to_remove, axis=1)\n",
    "\n",
    "print(f\"Shape of the new training set: {x_train_new.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the new training set: (328135, 137)\n"
     ]
    }
   ],
   "source": [
    "# removing columns with more than 70% of NaN values\n",
    "x_train_clean = x_train_new.copy()\n",
    "x_train_clean, columns_to_keep = remove_nan(x_train_clean, 0.70)\n",
    "print(f\"Shape of the new training set: {x_train_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves us with 137 features. **we don't have the ID of the remaining features so we cannot look at them one by one**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "Variables that are highly correlated (e.g., above 80%) might be redundant and can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = compute_corr(x_train_clean)\n",
    "plot_corr_matrix(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
